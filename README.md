# Transformer

PyTorch implementation of [Attention is All You Need](https://arxiv.org/abs/1706.03762) paper by Vaswani et al. This repository is mainly for me to learn more about NLP and to further my understanding of the underlying architecture of current LLMs.

## References:
- [Attention is All You Need](https://arxiv.org/abs/1706.03762)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
- [Language Translation with nn.Transformer and torchtext](https://pytorch.org/tutorials/beginner/translation_transformer.html)